{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "using LaTeXStrings\n",
    "using Lux, MLUtils, Optimisers, Zygote, OneHotArrays, Random, Statistics, Printf, Reactant\n",
    "#using MLDatasets: MNIST\n",
    "using SimpleChains: SimpleChains\n",
    "using JLD2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ec0d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Matrix} with 4 entries:\n",
       "  0 => [1 0; 0 1]\n",
       "  2 => Complex{Int64}[0+0im 0-1im; 0+1im 0+0im]\n",
       "  3 => [1 0; 0 -1]\n",
       "  1 => [0 1; 1 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "particles = 3 # number of qubits\n",
    "d = 2^particles # dimension of the Hilbert space\n",
    "\n",
    "# Matrices de Pauli, será nuestra base. \n",
    "sigmax = [0 1; 1 0]\n",
    "sigmay = [0 -im; im 0]\n",
    "sigmaz = [1 0; 0 -1]\n",
    "id= [1 0; 0 1] # Matriz identidad\n",
    "\n",
    "Sigma = Dict(0 => id, 1 => sigmax, 2 => sigmay, 3 => sigmaz) #Diccionario para llamar a las matrices de Pauli\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75772930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{UnitRange{Int64}}:\n",
       " 0:3\n",
       " 0:3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 2 # Número de operadores locales que queremos generar\n",
    "\n",
    "list=[0:3 for _ in 1:k] # Arreglo de tres secuencias de 0 a 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d01856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Any}:\n",
       " [1.0, 0.0, 0.0]\n",
       " [2.0, 0.0, 0.0]\n",
       " [3.0, 0.0, 0.0]\n",
       " [0.0, 1.0, 0.0]\n",
       " [1.0, 1.0, 0.0]\n",
       " [2.0, 1.0, 0.0]\n",
       " [3.0, 1.0, 0.0]\n",
       " [0.0, 2.0, 0.0]\n",
       " [1.0, 2.0, 0.0]\n",
       " [2.0, 2.0, 0.0]\n",
       " [3.0, 2.0, 0.0]\n",
       " [0.0, 3.0, 0.0]\n",
       " [1.0, 3.0, 0.0]\n",
       " [2.0, 3.0, 0.0]\n",
       " [3.0, 3.0, 0.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generamos una lista de combinaciones de los operador local A1 \n",
    "place = 1 # Se utiliza para considerar la interacción entre el primer y segundo qubit (Los elementos de A1) \n",
    "test_visual_list = []\n",
    "\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "\n",
    "ArrayA1 = test_visual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31899ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Any}:\n",
       " [0.0, 1.0, 0.0]\n",
       " [0.0, 2.0, 0.0]\n",
       " [0.0, 3.0, 0.0]\n",
       " [0.0, 0.0, 1.0]\n",
       " [0.0, 1.0, 1.0]\n",
       " [0.0, 2.0, 1.0]\n",
       " [0.0, 3.0, 1.0]\n",
       " [0.0, 0.0, 2.0]\n",
       " [0.0, 1.0, 2.0]\n",
       " [0.0, 2.0, 2.0]\n",
       " [0.0, 3.0, 2.0]\n",
       " [0.0, 0.0, 3.0]\n",
       " [0.0, 1.0, 3.0]\n",
       " [0.0, 2.0, 3.0]\n",
       " [0.0, 3.0, 3.0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "place = 2 # Se utiliza para considerar la interacción entre el segundo y tercero qubit (Los elementos de A2)\n",
    "\n",
    "test_visual_list = [] # Se tiene que volver a definir esta lista como una lista vacía \n",
    "\n",
    "for i in Base.product(list...)\n",
    "    total_list=zeros(particles)\n",
    "    total_list[place:place+k-1]= i|>collect\n",
    "    if sum(total_list) != 0\n",
    "        ##print(total_list)\n",
    "        push!(test_visual_list,total_list)\n",
    "    end\n",
    "   # print(\"\\n\")\n",
    "end\n",
    "\n",
    "ArrayA2 = test_visual_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb3d1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores aleatorios. (1000 datos)\n",
    "c = rand(2,1000)*2 .-1 # Estos son los valores de y, los que queremos predecir, cada columna es un valor de y (contiene dos elementos)\n",
    "\n",
    "xaleatMat1 = rand(2,length(ArrayA1)).*2 .-1 \n",
    "\n",
    "A1P = zeros(2^particles, 2^particles)  # Un arreglo vacío para almacenar matrices\n",
    "A2P = zeros(2^particles, 2^particles)  # Un arreglo vacío para almacenar matrices\n",
    "\n",
    "for k in 1:length(ArrayA1)\n",
    "    A1P += xaleatMat1[1,k] * kron([Sigma[ArrayA1[k][j]] for j in eachindex(ArrayA1[1])]...)\n",
    "end\n",
    "\n",
    "for k in 1:length(ArrayA2)\n",
    "    A2P += xaleatMat1[2,k]*kron([Sigma[ArrayA2[k][i]] for i in eachindex(ArrayA2[1])]...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e3ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda lo que haremos es generar un vector de tuplas con la información (x,y) donde x es un vector   \n",
    "# que contiene los promedios a1 y a2 con el estado 0,1,2,... después el vector y tendrá los valores c1 y c2 \n",
    "# estos valores se repetirán para todos los estados y promedios que consideramos del mismo Hamiltoniano, \n",
    "# es decir, si tenemos 4 estados y 2 promedio por estado, se repetirán 4 veces lso valores de y: c1 y c2\n",
    "# Tomamos para x la mitad de los estados del sistema\n",
    "\n",
    "n = 1000 # Número de datos que queremos generar \n",
    "\n",
    "# Inicializamos un vector vacío para almacenar las 1000 tuplas \n",
    "Tup = []\n",
    "\n",
    "for k in 1 : n\n",
    "\n",
    "    mat1a1 = zeros(2) # Colocamos un vector de ceros que se va a reiniciar en cada paso \n",
    "\n",
    "    # Formamos el Hamiltoniano\n",
    "    H12 = c[1,k]*A1P + c[2,k]*A2P\n",
    "\n",
    "    # Tomamos los vectores propios \n",
    "\n",
    "    vor  = eigen(H12).vectors\n",
    "    adjvor = adjoint(vor)\n",
    "\n",
    "    vor[:,1] # Este es el primer vector propio, los vectores propios con eigen se colocan en columnas \n",
    "    adjvor[1,:] # Este es el primer vector propio para la adjunta (Recordemos es un vector izquierdo [Fila])\n",
    "\n",
    "    # Calculamos el valor esperado de la primera mitad de vectores propios\n",
    "\n",
    "    ExpValA = zeros(ComplexF64, Int((size(vor)[1])/2))\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValA[i] = transpose(adjvor[i,:])*A1P*vor[:,i]\n",
    "    end\n",
    "\n",
    "    ExpValB = zeros(ComplexF64,Int((size(vor)[1])/2))  # ExpVal2[1] = a21 = \\bra{\\phi1_}A_2\\ket{\\phi_1}\n",
    "    for i in 1:Int((size(vor)[1])/2)\n",
    "        ExpValB[i] = transpose(adjvor[i,:])*A2P*vor[:,i]\n",
    "    end\n",
    "\n",
    "\n",
    "\n",
    "    #tk = (mat1a1, c[:,k]) # Generamos una tupla con un vector que tiene 2 promedios y un vector con c1 y c2 para el respectivo Hamiltoniano\n",
    "    #push!(Tup,tk) # Agregar la tupla al vector \n",
    "\n",
    "    for i in 1:4\n",
    "        tk = ([real(ExpValA[i]), real(ExpValB[i])], c[:, k])\n",
    "        push!(Tup, tk)\n",
    "    end\n",
    "   # ValsCompleto = vcat(ValsA, ValsB) # Por último nuestro vector tendrá la forma de 8x1, para poder agregarlo al batch \n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7342d0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loadata (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function loadata(batchsize, train_split)\n",
    "    # Separar la tupla anterior en los dos batches de datos, los elementos de x y los de y. \n",
    "\n",
    "    # Extract inputs (x) and outputs (y) from the tuples\n",
    "    x_batch = reduce(hcat, getindex.(Tup, 1)) #cat(map(t -> t[1], Tup)...; dims=2) \n",
    "    y_batch = reduce(hcat, getindex.(Tup, 2))#cat(map(t -> t[2], Tup)...; dims=2)  # Stack outputs along the 2nd dimension (batch)\n",
    "    (x_train, y_train), (x_test, y_test) = splitobs((x_batch, y_batch); at=train_split) # Separa los datos en train y test\n",
    "\n",
    "    return (\n",
    "        # Use DataLoader to automatically minibatch and shuffle the data\n",
    "        DataLoader(collect.((x_train, y_train)); batchsize, shuffle=true, partial=false),\n",
    "        # Don't shuffle the test data\n",
    "        DataLoader(collect.((x_test, y_test)); batchsize, shuffle=false, partial=false),\n",
    "    )\n",
    "end\n",
    "\n",
    "# batchsize será el tamaño del subconjunto de datos\n",
    "# train_split, en decimal, el porcentaje de datos que se utilizarán para entrenamiento, el complemento será para test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3b6a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "    layer_1 = Dense(2 => 64),           \u001b[90m# 192 parameters\u001b[39m\n",
       "    layer_2 = Dense(64 => 32, myleakyrelu),  \u001b[90m# 2_080 parameters\u001b[39m\n",
       "    layer_3 = Dense(32 => 2),           \u001b[90m# 66 parameters\u001b[39m\n",
       ") \u001b[90m        # Total: \u001b[39m2_338 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myleakyrelu(x) = leakyrelu(x,0.1)\n",
    "\n",
    "model = Chain(\n",
    "    Dense(2,64),\n",
    "    Dense(64,32,myleakyrelu),\n",
    "    Dense(32,2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cce21afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_fn (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Función de pérdida\n",
    "\n",
    "CosineSimilarity(x,y) = sum(x.*y)/sqrt(sum(x.^2)*sum(y.^2)) # x, y no son los mismos que los del modelo\n",
    "function myloss(x,y)\n",
    "    return 1 - CosineSimilarity(x,y)\n",
    "end\n",
    "\n",
    "function loss_fn(model,ps,st,d)\n",
    "    x,y = d\n",
    "    ŷ,stn = model(x,ps,st)\n",
    "\n",
    "    return myloss(ŷ,y),stn,(;)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "181f868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleChainsLayer(\n",
       "    Chain(\n",
       "        layer_1 = Dense(2 => 64),       \u001b[90m# 192 parameters\u001b[39m\n",
       "        layer_2 = Dense(64 => 32, myleakyrelu),  \u001b[90m# 2_080 parameters\u001b[39m\n",
       "        layer_3 = Dense(32 => 2),       \u001b[90m# 66 parameters\u001b[39m\n",
       "    ),\n",
       ") \u001b[90m        # Total: \u001b[39m2_338 parameters,\n",
       "\u001b[90m          #        plus \u001b[39m0 states."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaptor = ToSimpleChainsAdaptor((2,))  # forma de entrada\n",
    "simple_chains_model = adaptor(model)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e14153b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accuracy (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const lossfn = loss_fn\n",
    "# const lossfn = CrossEntropyLoss(; logits=Val(true)) # const se usa para decirle a Julia que el tipo de la variable global no va a cambiar: https://docs.julialang.org/en/v1/base/base/#const\n",
    "function accuracy(model, ps, st, dataloader)\n",
    "    total_correct, total = 0, 0\n",
    "    st = Lux.testmode(st) # Se configura el modelo para hacer inferencia.\n",
    "    for (x, y) in dataloader\n",
    "        target_class = onecold(Array(y)) # Es tomar el elemento con mayor probabilidad. Equivalentemente es softmax con temperature cero.\n",
    "        predicted_class = onecold(Array(first(model(x, ps, st)))) # Es tomar el elemento con mayor probabilidad. Equivalentemente es softmax con temperature cero.\n",
    "        total_correct += sum(target_class .== predicted_class)\n",
    "        total += length(target_class)\n",
    "    end\n",
    "    return total_correct / total\n",
    "end\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a84bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(:eta, :beta, :epsilon)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fieldnames(Adam) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295b042c",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: `@compile` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nin expression starting at d:\\Git\\MCSN\\MCSN_OUT\\Proyecto\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:11",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: `@compile` not defined in `Main`\n",
      "Suggestion: check for spelling errors or missing imports.\n",
      "in expression starting at d:\\Git\\MCSN\\MCSN_OUT\\Proyecto\\jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X16sZmlsZQ==.jl:11\n"
     ]
    }
   ],
   "source": [
    "function train(model, dev=cpu_device(); rng=Random.default_rng(), kwargs...)\n",
    "    train_dataloader, test_dataloader = dev(loadata(100, 0.9))\n",
    "    ps, st = dev(Lux.setup(rng, model)) # se inicializan los parámetros del modelo de forma aleatoria y se cargan en el CPU (dev)\n",
    "\n",
    "    vjp = dev isa ReactantDevice ? AutoEnzyme() : AutoZygote() # Usando Reactant permite compilar el modelo antes de entrenarlo: https://lux.csail.mit.edu/stable/manual/compiling_lux_models#reactant-compilation\n",
    "\n",
    "    train_state = Training.TrainState(model, ps, st, Adam(3.0f-4)) \n",
    "\n",
    "    if dev isa ReactantDevice\n",
    "        x_ra = first(test_dataloader)[1]\n",
    "        model_compiled = @compile model(x_ra, ps, Lux.testmode(st)) # Justo aquí es compilado el modelo\n",
    "    else\n",
    "        model_compiled = model\n",
    "    end\n",
    "\n",
    "    ### Lets train the model\n",
    "    nepochs = 10 # Cuantas veces se pasa por todos los datos\n",
    "    tr_acc, te_acc = 0.0, 0.0 # Se inicializan las variables de accuracy\n",
    "    for epoch in 1:nepochs\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader # Dos preguntas: x y y ya son arreglos o son otro objeto? y en cada evaluación se reordenan?\n",
    "            _, _, _, train_state = Training.single_train_step!(\n",
    "                vjp, lossfn, (x, y), train_state\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        tr_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, train_dataloader\n",
    "            ) * 100\n",
    "        te_acc =\n",
    "            accuracy(\n",
    "                model_compiled, train_state.parameters, train_state.states, test_dataloader\n",
    "            ) * 100\n",
    "\n",
    "        @printf \"[%2d/%2d] \\t Time %.2fs \\t Training Accuracy: %.2f%% \\t Test Accuracy: \\\n",
    "                 %.2f%%\\n\" epoch nepochs ttime tr_acc te_acc\n",
    "    end\n",
    "\n",
    "    return train_state.parameters, train_state.states, tr_acc, te_acc # En el código del tutorial no están las primeras dos variables, lo modifiqué para que nos devuelva los parámetros entrenados.\n",
    "end\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ab69e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 2 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function train(model, dev=cpu_device(); rng=Random.default_rng(), kwargs...)\n",
    "    train_dataloader, test_dataloader = dev(loadata(100, 0.9))\n",
    "    ps, st = dev(Lux.setup(rng, model)) # inicializa los parámetros y estados en el dispositivo dev\n",
    "\n",
    "    # Siempre se usará AutoZygote en lugar de AutoEnzyme (porque no se usa Reactant)\n",
    "    vjp = AutoZygote()\n",
    "\n",
    "    train_state = Training.TrainState(model, ps, st, Adam(3.0f-4))\n",
    "    \n",
    "    # Se asigna el modelo tal cual, sin compilación especial\n",
    "    model_compiled = model\n",
    "\n",
    "    ### Bucle de entrenamiento\n",
    "    nepochs = 10 # Cuántas veces se pasa por todos los datos\n",
    "    tr_acc, te_acc = 0.0, 0.0\n",
    "    for epoch in 1:nepochs\n",
    "        stime = time()\n",
    "        for (x, y) in train_dataloader\n",
    "            _, _, _, train_state = Training.single_train_step!(\n",
    "                vjp, lossfn, (x, y), train_state\n",
    "            )\n",
    "        end\n",
    "        ttime = time() - stime\n",
    "\n",
    "        tr_acc = accuracy(\n",
    "            model_compiled, train_state.parameters, train_state.states, train_dataloader\n",
    "        ) * 100\n",
    "        te_acc = accuracy(\n",
    "            model_compiled, train_state.parameters, train_state.states, test_dataloader\n",
    "        ) * 100\n",
    "\n",
    "        @printf \"[%2d/%2d] \\t Time %.2fs \\t Training Accuracy: %.2f%% \\t Test Accuracy: %.2f%%\\n\" epoch nepochs ttime tr_acc te_acc\n",
    "    end\n",
    "\n",
    "    return train_state.parameters, train_state.states, tr_acc, te_acc\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b40d8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: `ReactantDevice` is not loaded or not functional. Load `Reactant.jl` before calling this function. Defaulting to CPU.\n",
      "└ @ MLDataDevices C:\\Users\\52331\\.julia\\packages\\MLDataDevices\\gyWcF\\src\\public.jl:247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] \t Time 33.27s \t Training Accuracy: 64.14% \t Test Accuracy: 60.50%\n",
      "[ 2/10] \t Time 0.00s \t Training Accuracy: 84.11% \t Test Accuracy: 80.00%\n",
      "[ 3/10] \t Time 0.02s \t Training Accuracy: 86.58% \t Test Accuracy: 86.00%\n",
      "[ 4/10] \t Time 0.01s \t Training Accuracy: 83.67% \t Test Accuracy: 84.25%\n",
      "[ 5/10] \t Time 0.04s \t Training Accuracy: 84.44% \t Test Accuracy: 85.25%\n",
      "[ 6/10] \t Time 0.02s \t Training Accuracy: 85.53% \t Test Accuracy: 86.75%\n",
      "[ 7/10] \t Time 0.03s \t Training Accuracy: 86.39% \t Test Accuracy: 87.75%\n",
      "[ 8/10] \t Time 0.02s \t Training Accuracy: 87.44% \t Test Accuracy: 88.25%\n",
      "[ 9/10] \t Time 0.01s \t Training Accuracy: 87.83% \t Test Accuracy: 88.50%\n",
      "[10/10] \t Time 0.01s \t Training Accuracy: 88.06% \t Test Accuracy: 88.25%\n"
     ]
    }
   ],
   "source": [
    "tr_acc, te_acc = train(model, reactant_device()); # entrenando el modelo en lux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279b12fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] \t Time 50.97s \t Training Accuracy: 84.31% \t Test Accuracy: 82.00%\n",
      "[ 2/10] \t Time 0.00s \t Training Accuracy: 83.81% \t Test Accuracy: 83.00%\n",
      "[ 3/10] \t Time 0.00s \t Training Accuracy: 84.53% \t Test Accuracy: 84.00%\n",
      "[ 4/10] \t Time 0.04s \t Training Accuracy: 84.75% \t Test Accuracy: 84.25%\n",
      "[ 5/10] \t Time 0.00s \t Training Accuracy: 85.31% \t Test Accuracy: 85.00%\n",
      "[ 6/10] \t Time 0.01s \t Training Accuracy: 85.94% \t Test Accuracy: 85.25%\n",
      "[ 7/10] \t Time 0.00s \t Training Accuracy: 86.97% \t Test Accuracy: 88.00%\n",
      "[ 8/10] \t Time 0.02s \t Training Accuracy: 87.78% \t Test Accuracy: 88.25%\n",
      "[ 9/10] \t Time 0.00s \t Training Accuracy: 88.25% \t Test Accuracy: 88.25%\n",
      "[10/10] \t Time 0.02s \t Training Accuracy: 88.64% \t Test Accuracy: 89.00%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ps, st, tr_acc, te_acc = train(simple_chains_model); #entrenando el modelo de simple simple_chains_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a82ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.3",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
